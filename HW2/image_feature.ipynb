{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vryXqEjDN0-Y"
   },
   "source": [
    "## 提取資料path和label到array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xF4EkK_C_7O5"
   },
   "outputs": [],
   "source": [
    "\n",
    "y_train=[]\n",
    "train_paths=[]\n",
    "\n",
    "\n",
    "# Read text file containing image paths\n",
    "with open('train.txt', 'r') as f:\n",
    "    for line in f.readlines():  \n",
    "    # print(line[:-1].split(' '))\n",
    "        image_train = line[:-1].split(' ')\n",
    "\n",
    "        train_paths.append(str(image_train[0]))\n",
    "        y_train.append(image_train[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-E1M8SP9s-yE"
   },
   "outputs": [],
   "source": [
    "y_test=[]\n",
    "test_paths=[]\n",
    "\n",
    "# Read text file containing image paths\n",
    "with open('test.txt', 'r') as f:\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    for line in f.readlines():  \n",
    "        # print(line[:-1].split(' '))\n",
    "        image_test = line[:-1].split(' ') \n",
    "\n",
    "        test_paths.append(image_test[0])\n",
    "        y_test.append(image_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-E1M8SP9s-yE"
   },
   "outputs": [],
   "source": [
    "y_val=[]\n",
    "val_paths=[]\n",
    "\n",
    "# Read text file containing image paths\n",
    "with open('val.txt', 'r') as f:\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    for line in f.readlines():  \n",
    "        # print(line[:-1].split(' '))\n",
    "        image_val = line[:-1].split(' ') \n",
    "\n",
    "        val_paths.append(image_val[0])\n",
    "        y_val.append(image_val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 用於Lenet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(path, featureList):\n",
    "\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = img.astype(np.float32).reshape(32, 32, 1) / 255.0\n",
    "    featureList.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HOG用於perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "# 設定 HOG 參數\n",
    "orientations = 9\n",
    "pixels_per_cell = (32, 32)\n",
    "cells_per_block = (3, 3)\n",
    "#設定圖片大小\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "\n",
    "def extract_histogram(image_path):\n",
    "    \n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    hog_features = hog(image, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block)\n",
    "\n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb16bb249a04645b926aea932a276a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.4 s, sys: 2.83 s, total: 37.2 s\n",
      "Wall time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#訓練集\n",
    "\n",
    "x_train=[] #hog\n",
    "x_train_lenet=[] #lenet5\n",
    "\n",
    "with tqdm(total=len(train_paths)) as pbar:\n",
    "    for path in train_paths:\n",
    "        try:\n",
    "            #hog\n",
    "            features = extract_histogram(path)\n",
    "            x_train.append(features)\n",
    "            #lenet5\n",
    "            get_training_data(path, x_train_lenet)\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        finally:\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a6b99a2a9e4cb88f9d73d745fa77c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 262 ms, sys: 20.6 ms, total: 283 ms\n",
      "Wall time: 280 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#測試集\n",
    "\n",
    "x_test=[] #hog\n",
    "x_test_lenet=[] #lenet\n",
    "\n",
    "with tqdm(total=len(test_paths)) as pbar:\n",
    "    for path in test_paths:\n",
    "        try:\n",
    "            #hog\n",
    "            features = extract_histogram(path)\n",
    "            x_test.append(features)\n",
    "            #lenet\n",
    "            get_training_data(path, x_test_lenet)\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        finally:\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3aa9c89feab4106a263af5db956d4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 296 ms, sys: 27.1 ms, total: 323 ms\n",
      "Wall time: 365 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#驗證集\n",
    "\n",
    "x_val=[] #hog\n",
    "x_val_lenet=[] #lenet\n",
    "\n",
    "with tqdm(total=len(val_paths)) as pbar:\n",
    "    for path in val_paths:\n",
    "        try:\n",
    "            #hog\n",
    "            features = extract_histogram(path)\n",
    "            x_val.append(features)\n",
    "            #lenet\n",
    "            get_training_data(path, x_val_lenet)\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        finally:\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徵儲存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* feature用於lenet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 32, 32, 1)\n",
      "(450, 32, 32, 1)\n",
      "(63325, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test_lenet=np.array(x_test_lenet)\n",
    "x_val_lenet=np.array(x_val_lenet)\n",
    "x_train_lenet=np.array(x_train_lenet)\n",
    "\n",
    "print(x_test_lenet.shape)\n",
    "print(x_val_lenet.shape)\n",
    "print(x_train_lenet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('feature/train_features_lenet',x_train_lenet)\n",
    "np.save('feature/val_features_lenet',x_val_lenet)\n",
    "np.save('feature/test_features_lenet',x_test_lenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* feature用於hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_np = np.array(x_train, dtype=object)\n",
    "x_test_np = np.array(x_test, dtype=object)\n",
    "x_val_np = np.array(x_val, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('feature/train_features',x_train_np)\n",
    "np.save('feature/val_features',x_val_np)\n",
    "np.save('feature/test_features',x_test_np)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* label儲存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('feature/train_labels',y_train)\n",
    "np.save('feature/val_labels',y_val)\n",
    "np.save('feature/test_labels',y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
